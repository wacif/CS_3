
# Pre-Lecture Activities for Students

### **Objective:**  
To familiarize students with NLP concepts like annotation and evaluation by interacting with LLMs and analyzing their responses.

---

### **Activity 1: Part-of-Speech (POS) Tagging**
**Prompt to LLM:**  
"Identify the part of speech for each word in the following sentence: 'The quick brown fox jumps over the lazy dog.'"

**Student Task:**  
1. Run the prompt in an LLM and observe the response.  
2. Compare the LLM's output with your own understanding of POS tagging.  
3. Reflect: Why is POS tagging important for NLP tasks?

---

### **Activity 2: Named Entity Recognition (NER)**
**Prompt to LLM:**  
"Extract and classify the named entities in the following sentence: 'Elon Musk founded SpaceX in Hawthorne, California, in 2002.'"

**Student Task:**  
1. Run the prompt and observe the LLM's response.  
2. Identify the entities (e.g., person, organization, location, date).  
3. Reflect: How could NER be useful in real-world applications like search engines or customer support?

---

### **Activity 3: Sentiment Analysis**
**Prompt to LLM:**  
"Analyze the sentiment of the following text: 'I absolutely loved the movie! The acting was superb, and the plot kept me on the edge of my seat.'"

**Student Task:**  
1. Run the prompt and observe the LLM's sentiment analysis (e.g., positive, negative, neutral).  
2. Reflect: How accurate do you think the LLM's sentiment analysis is? Can you think of cases where sentiment analysis might fail?

---

### **Activity 4: Dependency Parsing**
**Prompt to LLM:**  
"Explain the grammatical relationships between the words in the sentence: 'She gave him a book.'"

**Student Task:**  
1. Run the prompt and observe the LLM's explanation of dependencies (e.g., subject, object, verb).  
2. Reflect: How does understanding dependencies help machines process human language?

---

### **Activity 5: Coreference Resolution**
**Prompt to LLM:**  
"Resolve the pronouns in the following text: 'John said he is tired because he worked all day.'"

**Student Task:**  
1. Run the prompt and observe how the LLM resolves the pronouns (e.g., "he" refers to "John").  
2. Reflect: Why is coreference resolution important for tasks like summarization or question answering?

---

### **Activity 6: Evaluation Metrics**
**Prompt to LLM:**  
"Explain the difference between precision, recall, and F1-score in the context of a spam detection system."

**Student Task:**  
1. Run the prompt and observe the LLM's explanation.  
2. Reflect: Why is it important to use multiple evaluation metrics instead of just accuracy?

---

### **Activity 7: BLEU and ROUGE Scores**
**Prompt to LLM:**  
"Compare the following machine-generated translation with the reference translation and explain how BLEU score would evaluate it:  
- Machine Translation: 'The cat is on the mat.'  
- Reference Translation: 'The cat sits on the mat.'"

**Student Task:**  
1. Run the prompt and observe the LLM's explanation of BLEU score.  
2. Reflect: How does BLEU help improve machine translation systems?

---

### **Activity 8: Perplexity**
**Prompt to LLM:**  
"Explain what perplexity means in the context of a language model predicting the next word in a sentence."

**Student Task:**  
1. Run the prompt and observe the LLM's explanation.  
2. Reflect: Why is low perplexity desirable for language models?

---

### **Activity 9: Real-World Application**
**Prompt to LLM:**  
"Give an example of how NLP is used in a real-world application like customer support chatbots."

**Student Task:**  
1. Run the prompt and observe the LLM's response.  
2. Reflect: What annotation and evaluation steps do you think were involved in building such a chatbot?

---

### **Activity 10: Challenge the LLM**
**Prompt to LLM:**  
"Can you generate a summary of the following text? 'The quick brown fox jumps over the lazy dog. The dog, feeling lazy, did not react.'"

**Student Task:**  
1. Run the prompt and observe the summary generated by the LLM.  
2. Reflect: How would you evaluate the quality of the summary? What metrics (e.g., ROUGE) could be used?

---

### **Follow-Up Questions for Students:**
1. What did you learn about annotation and evaluation from interacting with the LLM?  
2. Were there any cases where the LLM's response surprised you or seemed incorrect?  
3. How do you think annotation and evaluation contribute to the development of reliable NLP systems?  

---


**Happy Learning!**